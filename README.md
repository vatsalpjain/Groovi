# ğŸµ Groovi - Real-Time Voice AI Music Assistant

<div align="center">

**Voice-first AI music assistant with wake word detection, real-time speech processing, and AI agent-based recommendations via Model Context Protocol (MCP)**

[Voice AI](#ï¸-voice-ai-architecture) â€¢ [MCP Integration](#-mcp-integration) â€¢ [AI Agent](#-ai-agent-workflow) â€¢ [Installation](#-installation)

</div>

---

## ğŸ“– Table of Contents

- [About](#-about)
- [ğŸ™ï¸ Voice AI Architecture](#ï¸-voice-ai-architecture) â­
- [ğŸ”Œ MCP Integration](#-mcp-integration)
- [ğŸ¤– AI Agent Workflow](#-ai-agent-workflow)
- [Tech Stack](#-tech-stack)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Running the App](#-running-the-app)
- [Project Structure](#-project-structure)
- [Troubleshooting](#-troubleshooting)

---

## ğŸ¯ About

**Groovi** is a **real-time voice AI music assistant** demonstrating advanced voice processing, Model Context Protocol (MCP) integration, and AI agent-based music discovery.

### Key Features

1. **ğŸ¤ Full Voice-to-Voice Pipeline** - Wake word â†’ STT â†’ LLM â†’ TTS (real-time, mostly local)
2. **ğŸ”Œ MCP-Based Architecture** - Spotify integration via Model Context Protocol
3. **ğŸ¤– AI Agent with Function Calling** - Iterative music discovery using Groq LLM
4. **âš¡ WebSocket Real-Time Processing** - Streaming audio processing
5. **ğŸ¯ Custom Wake Word** - "Hey Groovi" detection

### How It Works

1. **Say "Hey Groovi"** - Custom wake word activates the assistant
2. **Speak Your Request** - VAD detects speech, Faster-Whisper transcribes
3. **AI Agent Explores** - Function-calling agent searches Spotify via MCP
4. **Groovi Responds** - Local Piper TTS speaks recommendations

---

## ğŸ™ï¸ Voice AI Architecture

Real-time voice-to-voice pipeline running via WebSocket.

### State Machine

```
WAKE_WORD (Idle) â†’ LISTENING (VAD + STT) â†’ PROCESSING (LLM + Agent) â†’ SPEAKING (TTS) â†’ Loop
```

### Components

| Component | Technology | Purpose | Latency |
|-----------|-----------|---------|---------|
| **Wake Word** | openWakeWord + Custom Model | "Hey Groovi" detection | < 100ms |
| **VAD** | Silero VAD | Speech/silence detection | 30ms |
| **STT** | Faster-Whisper (base) | Speech-to-text | ~500ms |
| **LLM** | Groq (Llama 3.1 8B) | Conversation + reasoning | ~300ms |
| **TTS** | Piper TTS (ONNX) | Text-to-speech | ~200ms |

**Total Latency**: ~1.1s | **Memory**: ~300MB

### WebSocket Protocol (`/ws/voice`)

**Client â†’ Server**: Binary PCM audio chunks (16kHz, 16-bit mono)

**Server â†’ Client Events**:
```json
{"event": "ready"}
{"event": "wake_word_detected"}
{"event": "listening"}
{"event": "speech_detected", "transcript": "..."}
{"event": "processing"}
{"event": "speaking", "text": "..."}
{"event": "audio", "data": <bytes>}  // TTS audio
{"event": "music_results", "tracks": [...]}
```

---

## ğŸ”Œ MCP Integration

Uses **Model Context Protocol** for Spotify integration - an open standard for AI-to-tool communication.

### Architecture

```
Backend AI Agent (Groq LLM)
    â†“ Function Calls
MCP Client (stdio)
    â†“ JSON-RPC
MCP Server (spotify_mcp/)
    â†“ Tool Execution
Spotify Web API
```

### MCP Server Tools

10 Spotify tools exposed via MCP:
- `search_tracks`, `search_artists`, `search_playlists`
- `get_artist_top_tracks`, `get_related_artists`
- `browse_new_releases`, `browse_genres`
- `create_playlist`, and more

**Transport**: Stdio (Standard I/O)  
**Protocol**: JSON-RPC 2.0  
**Connection**: Per-request spawning

---

## ğŸ¤– AI Agent Workflow

Autonomous AI agent using function calling to explore Spotify and curate recommendations.

**Model**: Llama 3.1 8B (via Groq)  
**Max Iterations**: 5  
**Strategy**: ReAct (Reasoning + Acting)

### Agent Loop

```python
while iteration < 5:
    # 1. LLM decides which tool to call
    response = groq_client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=conversation_history,
        tools=SPOTIFY_TOOLS
    )
    
    # 2. Execute tool via MCP
    result = await mcp_client.call_tool(tool_name, args)
    
    # 3. Agent refines or finishes
    if agent_done:
        break
```

**Example**: User says "energetic workout music"
- Iteration 1: Search tracks â†’ 15 results
- Iteration 2: Explore playlists â†’ Extract top tracks
- Iteration 3: Browse genres â†’ Diversify
- Result: 5 curated tracks with reasoning

---

## ğŸ› ï¸ Tech Stack

### Voice AI
- **Faster-Whisper** - Local STT (CTranslate2 optimized)
- **Piper TTS** - Local TTS (ONNX Runtime)
- **openWakeWord** - Custom wake word detection
- **Silero VAD** - Voice activity detection
- **PyTorch + ONNX** - ML inference engines

### Backend
- **FastAPI** - Async web framework
- **Groq** - LLM inference (Llama 3.1 8B)
- **MCP SDK** - Model Context Protocol
- **Spotipy** - Spotify API wrapper
- **Python 3.13**

### Frontend
- **React 18 + TypeScript**
- **Vite** - Build tool
- **Tailwind CSS v4**
- **WebSocket API**

---

## ğŸ“‹ Prerequisites

**Required Software**:
- Python 3.13+
- uv (Python package manager)
- Node.js 18+
- npm 9+

**API Keys**:
1. [Spotify Developer](https://developer.spotify.com/dashboard) - Client ID & Secret
2. [Groq Console](https://console.groq.com/) - API Key (free tier available)

---

## ğŸš€ Installation

### Backend Setup

```bash
cd backend

# Install uv (if not installed)
# Windows: powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
# macOS/Linux: curl -LsSf https://astral.sh/uv/install.sh | sh

# Install dependencies
uv sync

# Verify
uv run python -c "import faster_whisper, piper; print('âœ… Ready')"
```

### MCP Server Setup

```bash
cd spotify_mcp
uv sync
```

### Frontend Setup

```bash
cd frontend
npm install
```

---

## âš™ï¸ Configuration

Create `backend/.env`:

```env
# Spotify (REQUIRED)
SPOTIPY_CLIENT_ID=your_client_id
SPOTIPY_CLIENT_SECRET=your_client_secret
SPOTIPY_REDIRECT_URI=http://localhost:5000/callback

# Groq (REQUIRED)
GROQ_API_KEY=your_groq_api_key

# Optional
# WHISPER_MODEL_SIZE=base
# WAKE_WORD_THRESHOLD=0.5
```

**Get Spotify Keys**:
1. Go to [Spotify Dashboard](https://developer.spotify.com/dashboard)
2. Create app, add redirect URI: `http://localhost:5000/callback`
3. Copy Client ID & Secret

**Get Groq Key**:
1. Go to [Groq Console](https://console.groq.com/)
2. Create API key
3. Copy key (free tier: 30 requests/min)

---

## ğŸƒ Running the App

**Terminal 1 - Backend**:
```bash
cd backend
uv run python main.py
```

**Expected output**:
```
ğŸµ Starting Groovi Backend Server...
ğŸ“¡ Server: http://localhost:5000
ğŸ¤ Voice AI models ready
```

**Terminal 2 - Frontend**:
```bash
cd frontend
npm run dev
```

**Access**:
- ğŸ¯ App: http://localhost:5173
- ğŸ”§ API Docs: http://localhost:5000/docs

**First Run**: Models download (~300MB, 1-2 min). Cached afterwards.

---

## ğŸ“ Project Structure

```
groovi/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ voice_ai/              # ğŸ™ï¸ Voice AI Pipeline
â”‚   â”‚   â”œâ”€â”€ voice_assistant.py  # State machine orchestrator
â”‚   â”‚   â”œâ”€â”€ wake_word_service.py
â”‚   â”‚   â”œâ”€â”€ vad_service.py
â”‚   â”‚   â”œâ”€â”€ streaming_STT.py
â”‚   â”‚   â””â”€â”€ streaming_TTS.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ mcp_client.py      # MCP client
â”‚   â”‚   â”œâ”€â”€ music_agent.py     # AI agent
â”‚   â”‚   â”œâ”€â”€ mood_analyzer.py
â”‚   â”‚   â””â”€â”€ spotify_auth.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ Hey_Groovi.tflite  # Wake word model
â”‚   â”‚   â””â”€â”€ piper/             # TTS models
â”‚   â”œâ”€â”€ main.py                # FastAPI app
â”‚   â””â”€â”€ pyproject.toml
â”‚
â”œâ”€â”€ spotify_mcp/               # ğŸ”Œ MCP Server
â”‚   â”œâ”€â”€ server.py              # MCP server
â”‚   â”œâ”€â”€ spotify_api.py
â”‚   â””â”€â”€ pyproject.toml
â”‚
â”œâ”€â”€ frontend/                  # ğŸ¨ Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ services/
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ README.md
```

---

## ğŸ› Troubleshooting

**WebSocket connection failed**:
- Ensure backend running: `cd backend && uv run python main.py`
- Check port 5000 available

**Wake word not detecting**:
- Check model exists: `backend/models/Hey_Groov*.onnx`
- Speak clearly in quiet environment
- Lower threshold in `.env`: `WAKE_WORD_THRESHOLD=0.3`

**Spotify credentials error**:
- Verify `.env` exists in `backend/`
- No extra spaces in API keys
- Restart backend after changes

**Module not found**:
```bash
cd backend
uv sync
```

**MCP server spawn failed**:
```bash
cd spotify_mcp
uv sync
```

**Test backend**:
```bash
cd backend
uv run python tests/test_spotify.py
uv run python tests/test_local_audio.py
```

---

## ğŸ“ Resources

- [Faster-Whisper](https://github.com/guillaumekln/faster-whisper) - Optimized Whisper
- [Piper TTS](https://github.com/rhasspy/piper) - Local text-to-speech
- [MCP Specification](https://spec.modelcontextprotocol.io/) - Model Context Protocol
- [Groq Docs](https://console.groq.com/docs) - LLM inference

---

<div align="center">

**Built with â¤ï¸ using Voice AI + MCP**

**Groovi ğŸµâœ¨**

</div>
